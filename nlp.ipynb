{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Review Sentiment Analysis and Feedback\n",
    "This project focuses on building a machine learning model to analyze and classify customer reviews of restaurants as either positive or negative. The goal is to understand customer sentiments and provide actionable insights based on the textual feedback.\n",
    "\n",
    "## Project Overview\n",
    "Restaurants receive numerous reviews daily, and manually analyzing these reviews to gauge customer satisfaction can be time-consuming and inefficient. By leveraging Natural Language Processing (NLP) techniques and machine learning algorithms, this project automates the sentiment analysis process, enabling quick and accurate identification of customer opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "Description: Importing necessary libraries for data processing, machine learning, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2cb9ce-7e86-4aa8-9d7b-fe1d877c3f13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Preprocessing Data\n",
    "Loading the dataset and displaying the first few rows to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Use raw string literal to avoid issues with file path\n",
    "data = pd.read_csv('C:\\\\Users\\\\kumar\\\\Downloads\\\\Restaurant_Reviews.tsv', sep='\\t', quoting=3)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Cleaning Function\n",
    "Defining a function to clean and preprocess the text data, including removing HTML tags, non-letter characters, and stopwords, as well as applying stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text data\n",
    "def clean_text(review):\n",
    "    # Remove HTML tags\n",
    "    review = re.sub('<.*?>', ' ', review)  \n",
    "    # Keep only letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)  \n",
    "    # Convert to lowercase\n",
    "    review = review.lower()  \n",
    "    # Split into words\n",
    "    review = review.split()  \n",
    "    # Initialize PorterStemmer for stemming\n",
    "    ps = PorterStemmer()  \n",
    "    # Remove stopwords and apply stemming\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]  \n",
    "    # Join words back into a single string\n",
    "    review = ' '.join(review)  \n",
    "    return review\n",
    "\n",
    "# Cleaning all reviews in the dataset\n",
    "corpus = [clean_text(review) for review in data['Review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorization\n",
    "Converting the cleaned text into numerical features using TF-IDF Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the text data using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=1500)\n",
    "x = tfidf.fit_transform(corpus).toarray()\n",
    "\n",
    "# Defining the dependent variable\n",
    "y = data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting the Dataset\n",
    "Splitting the dataset into training and testing sets with an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building and Hyperparameter Tuning\n",
    "Building the RandomForestClassifier model and using GridSearchCV to tune hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    }
   ],
   "source": [
    "# Initializing the RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Defining the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 50, 100, None],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "Evaluating the model's performance using the confusion matrix, classification report, and accuracy score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85 12]\n",
      " [43 60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76        97\n",
      "           1       0.83      0.58      0.69       103\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.75      0.73      0.72       200\n",
      "weighted avg       0.75      0.72      0.72       200\n",
      "\n",
      "Accuracy: 72.50%\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = best_classifier.predict(x_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(cr)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sentiment Prediction Function\n",
    "Creating a function to predict whether a review is positive or negative based on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the sentiment of a review\n",
    "def predict_review(review):\n",
    "    # Clean the review text\n",
    "    cleaned_review = clean_text(review)\n",
    "    # Transform the review text into TF-IDF vector\n",
    "    review_vector = tfidf.transform([cleaned_review]).toarray()\n",
    "    # Predict sentiment using the best classifier\n",
    "    prediction = best_classifier.predict(review_vector)\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "# Example predictions\n",
    "print(predict_review(\"The food was excellent and the service was great!\"))\n",
    "print(predict_review(\"The food was horrible and the service was terrible.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Suggesting Areas of Improvement\n",
    "Defining a function to suggest improvements based on specific aspects like food, service, ambiance, and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Improve food']\n"
     ]
    }
   ],
   "source": [
    "# Function to suggest areas of improvement based on the review\n",
    "def suggest_improvements(review):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    aspects = {\n",
    "        'food': ['food', 'meal', 'dish', 'taste'],\n",
    "        'service': ['service', 'staff', 'waiter', 'waitress'],\n",
    "        'ambiance': ['ambiance', 'atmosphere', 'environment'],\n",
    "        'price': ['price', 'cost', 'value']\n",
    "    }\n",
    "    suggestions = []\n",
    "    cleaned_review = clean_text(review)\n",
    "    for aspect, keywords in aspects.items():\n",
    "        if any(word in cleaned_review for word in keywords):\n",
    "            sentiment_score = sia.polarity_scores(review)\n",
    "            if sentiment_score['neg'] > sentiment_score['pos']:\n",
    "                suggestions.append(f\"Improve {aspect}\")\n",
    "    return suggestions if suggestions else [\"No specific improvements needed\"]\n",
    "\n",
    "# Example suggestion\n",
    "print(suggest_improvements(\"The food was horrible and the service was terrible.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Full Review Analysis\n",
    "Combining sentiment prediction and improvement suggestions into a full analysis function for restaurant reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform full review analysis: sentiment prediction and improvement suggestions\n",
    "def full_review_analysis(review):\n",
    "    sentiment = predict_review(review)\n",
    "    suggestions = suggest_improvements(review) if sentiment == \"Negative\" else [\"No improvements needed\"]\n",
    "    return sentiment, suggestions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:  The food was horrible and the service was terrible.\n",
      "Review Sentiment: Negative\n",
      "Suggestions for Improvement:\n",
      "Improve food\n"
     ]
    }
   ],
   "source": [
    "# Example full analysis\n",
    "review1 = \"The food was horrible and the service was terrible.\"\n",
    "sentiment, suggestions = full_review_analysis(review1)\n",
    "print(\"Review 1: \", review1)\n",
    "print(f\"Review Sentiment: {sentiment}\")\n",
    "print(\"Suggestions for Improvement:\")\n",
    "for suggestion in suggestions:\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 2:  The food was good and the service was nice.\n",
      "Review Sentiment: Positive\n",
      "Suggestions for Improvement:\n",
      "No improvements needed\n"
     ]
    }
   ],
   "source": [
    "review2 = \"The food was good and the service was nice.\"\n",
    "print(\"Review 2: \", review2)\n",
    "sentiment, suggestions = full_review_analysis(review2)\n",
    "print(f\"Review Sentiment: {sentiment}\")\n",
    "print(\"Suggestions for Improvement:\")\n",
    "for suggestion in suggestions:\n",
    "    print(suggestion)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nlp",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
